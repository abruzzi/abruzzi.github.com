<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: ThoughtWorks | I code it]]></title>
  <link href="http://abruzzi.github.com/category/thoughtworks/atom.xml" rel="self"/>
  <link href="http://abruzzi.github.com/"/>
  <updated>2013-01-13T23:54:30+08:00</updated>
  <id>http://abruzzi.github.com/</id>
  <author>
    <name><![CDATA[Qiu Juntao]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[是时候慢下来了]]></title>
    <link href="http://abruzzi.github.com/2013/01/where-am-i/"/>
    <updated>2013-01-09T20:56:00+08:00</updated>
    <id>http://abruzzi.github.com/2013/01/where-am-i</id>
    <content type="html"><![CDATA[<p>某个晚上，我在网上为自己挑选一个适合出差的行李箱，两个小时之后，我突然发现我停留在了一个瑞士军刀的淘宝店里；本来计划晚上看看AppleScript的资料，结果一个小时之后，我在用python写一个opencv的小程序，又过了一个小时，我停留在Alfred的powerpack的支付页面，面对着15英镑的价格陷入沉思。</p>

<p>而且周围好像每个人都有这样类似的经历。我咨询其他同事遇到类似的情况怎么处理，有人推荐使用Todo列表，而且Todo最好列在纸上。当列表中的Todo被消灭时，会激发你去写下更多的task。这当然是个好办法，我很早的时候就写过一个软件来完成Todo管理：<a href="http://code.google.com/p/stodo/">sTodo</a>。但是当打开电脑之后，时间就完全不受控制了，网络上总是有各种各样好玩的东西，新的框架，新的语言，某种颠覆式的CSS框架，新奇而好用的软件，可以大大提高用户体验的UI库，太多了……。</p>

<p><img src="http://abruzzi.github.com/images/2013/01/stodo_edit.png" alt="sTodo" /></p>

<p>上周三的晚上，回家之后打开电脑，开始了“学习”，事实上是很盲目的在网络上游荡，当我意识到又要重蹈覆辙的时候，我毅然的合起了电脑，然后拿起一本纸质的《JavaScript: The good parts》。最后当我要睡觉时才发现，读了大概30多页，而且以前的一些概念也更加清楚了。而且事实上我并未因为没有打开计算机而有什么实质性的损失。</p>

<p>然后我突然意识到我之前的所谓的学习的方式有很大的问题，网络当然可以为你提供大量的信息，但是很多时候，这些呈碎片装的信息的作用并不如预期般的大。它会帮你解决手头的小问题，但是阻挡了你的视线，你本可以走的更远！</p>

<p>在网络上看资料，总是有一种紧迫感：这么多的东西都不会，落后于时代好多年。打开电脑，一个晚上过去了，你可能读了很多的东西，但是记下来的非常少，因为总是会被各种链接，图片等干扰，这个看似在学习的过程事实上完全是在浪费实践，一天之后，你前一个晚上看到的东西几乎被完全遗忘，然后周而复始。</p>

<p>所以，是时候慢下来，你不会因为没有浏览几个网页，或者少读几篇文章而落后于时代几十年的，你需要好多年才能积累起来的知识，别人同样需要好多年。</p>

<p><img src="http://abruzzi.github.com/images/2013/01/todos.png" alt="image" /></p>

<p>合上电脑，捧起纸质的书籍，世界突然慢了下来，但是却会充盈很多。事实上，放慢脚步，消除网络带来的<strong><em>虚假的紧迫感</em></strong>，反而可以以更快的速度掌握一项技术，一个框架，也可以让印象更加深刻。晚上回家尽量不带电脑，我用trainng经费购买的10本书，现在才读完2.5本，去年5月买的书还有两本没有读完，这些亏欠都需要在脱离电脑的舒服之后才能想起来，也才有可能完成。</p>

<p>慢下来。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[使用opencv进行数字识别]]></title>
    <link href="http://abruzzi.github.com/2013/01/basic-digits-recognization/"/>
    <updated>2013-01-05T22:51:00+08:00</updated>
    <id>http://abruzzi.github.com/2013/01/basic-digits-recognization</id>
    <content type="html"><![CDATA[<p>最终的效果图是这样的：</p>

<p><img src="http://abruzzi.github.com/images/2013/01/result.resized.png" alt="识别效果" /></p>

<p>图中的一个小的窗口中为resize之后的所有找到的图片的列表，在这个case中，有三个数字。</p>

<p>数字识别即将图片中的数字通过计算机算法识别为文本。如果要从头写一个识别器，可能需要很多的实践，花费很大的精力，而且还需要有良好的数学功底才能完成，不过使用opencv提供的丰富的API和算法实现，可以比较容易的做到，而且也可以得到比较高的精确率。</p>

<p>数字识别是模式识别中的一个特例，我这里要讨论的是一个比较简单的实现，基于最简单也最容易理解的KNN算法(请参看<a href="http://icodeit.org/blog/2013/01/k-nearest-neighbour/">之前的一篇文章</a>)。</p>

<p>数字识别和其他的所有计算机视觉相关的应用都会分为两个步骤：ROI抽取和识别。</p>

<pre><code>1. ROI抽取即将感兴趣的区域从原始图像中分离初来，这个步骤包括二值化，噪点的消除等
2. 识别即通过一些分类器将第一步中的结果进行分类，事实上属于机器学习的一个典型应用
</code></pre>

<h3>图像预处理</h3>

<p>原始图片中会有大量与目标无关的信息，比如人脸检测中，背景中往往有诸如桌椅，墙壁上的画，或者在户外的树木，动物等等，这些与目标无关的信息被称为噪音或者噪点，应该在进行分类之前通过一些特定的步骤来消除，不但可以减少计算量，而且还可以提高准确率。</p>

<p><img src="http://abruzzi.github.com/images/2013/01/865.origin.png" alt="原始图片" /></p>

<h4>灰度图</h4>

<p>通常的彩色图形由3个(RGB)或者4个(RGBA)通道组成，在计算机看来，一个彩色的图片是由3/4个矩阵组成，每个矩阵中包含若干个点(比如1024x768)，如果每个通道都参与运算的话，会引入太多的计算量，因此通常的做法是将彩色图像转换为灰度图，在opencv中，这一步非常容易：</p>

<p>```
def grayify(image):</p>

<pre><code>return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
</code></pre>

<p>```</p>

<h4>二值图</h4>

<p>灰度图较之原始图片，将三个维度的矩阵变成了一个维度，已经做了部分简化，但是算法来说，噪音并未消除，灰度图中，每个点仍然有8位来表示，每个点可能的灰度为0-255，二值图即将灰度图转换成黑白图，每个点只有两种可能：非黑即白，这样将大大简化计算。</p>

<p>opencv提供了阈值调节的API，可以将灰度图转换为二值图：高于某一个阈值的点被认为是白色，反之为黑色：</p>

<p>```
def thresholding_inv(image):</p>

<pre><code>gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

ret, bin = cv2.threshold(gray, 48, 255, cv.CV_THRESH_BINARY_INV)
bin = cv2.medianBlur(bin, 3)

return bin
</code></pre>

<p>```
上面的代码中，48即为阈值，如果灰度高于48，那么改点会被认为是255，否则为0。效果如下：
<img src="http://abruzzi.github.com/images/2013/01/865.thres.png" alt="二值图" /></p>

<p>由于轮廓检测算法需要从黑色的背景中搜索白色的轮廓，所有此处的<code>threshold</code>最后一项参数为<code>cv.CV_THRESH_BINARY_INV</code>，即反转黑白色。</p>

<h4>轮廓检测</h4>

<p>轮廓检测会将二值图中的可以连通的区域(一个多边形)用一系列的点描述，默认的轮廓检查会返回一个点的序列，比如用四个点描述一个矩形，但是可以通过设置精度来返回更多的点，这里我们只需要返回矩形即可：</p>

<p><img src="http://abruzzi.github.com/images/2013/01/865.contours.png" alt="轮廓检查" /></p>

<p>比较有意思的是这里的数字8，由于8这个形状中有两个圆圈，默认的轮廓检查会将这两个圆圈都检测到，那么8就会有三个轮廓，同样还可能出现这种情况的还有数字4,6,9。</p>

<p><code>
contours, heirs = cv2.findContours(thres.copy(), \
cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)
</code></p>

<p>因此需要指定<code>findContours</code>函数仅搜索最外层的轮廓，而不关注内部可能出现的任何轮廓：</p>

<p><code>
contours, heirs = cv2.findContours(thres.copy(), \
cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
</code></p>

<h3>KNN分类算法</h3>

<p>KNN算法的原理可以参看之前的<a href="http://icodeit.org/blog/2013/01/k-nearest-neighbour/">一篇文章</a>。这里的实现主要参考了opencv的示例程序:</p>

<p>```
class KNearest(StatModel):</p>

<pre><code>def __init__(self, k = 3):
    self.k = k
    self.model = cv2.KNearest()

def train(self, samples, responses):
    self.model = cv2.KNearest()
    self.model.train(samples, responses)

def predict(self, samples):
    retval, results, neigh_resp, dists = \
    self.model.find_nearest(samples, self.k)
    return results.ravel()
</code></pre>

<p>```</p>

<h4>数字的顺序</h4>

<p>另外一个有意思的事情是轮廓检测的时候，算法并不一定按照从左到右，从上到下的方向进行，我开始只是简单的按照迭代的顺序将结果插入到一个list中，但是这样list中的结果是乱的，下午得到了team中有图像处理背景的杨眉同学的支持：搜索到轮廓的时候，将此时的position信息与轮廓一起记录下来，然后在搜索完成之后，将整个列表按照x坐标排序(卡上的数字是按照从左向右书写)：</p>

<p>```
class PosImage(object):</p>

<pre><code>def __init__(self, pos, image):
    self.pos = pos
    self.image = image

def get_position(self):
    return self.pos

def get_image(self):
    return self.image
</code></pre>

<p>```</p>

<p>然后在迭代中记录position信息：</p>

<p>```</p>

<pre><code>cropped = gray[y:y+h, x:x+w]
resized = cv2.resize(cropped, (20, 20))
cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 3)
pos_image = PosImage((x, y), resized)
images.append(pos_image)
</code></pre>

<p>```</p>

<p>最后做一次新的arrange：</p>

<p>```
def rearrange(images):</p>

<pre><code>return sorted(images, cmp=lambda x, y:
cmp(x.get_position()[0], y.get_position()[0]))
</code></pre>

<p>```</p>
]]></content>
  </entry>
  
</feed>
