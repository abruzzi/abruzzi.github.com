<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Lean | I code it]]></title>
  <link href="http://abruzzi.github.com/category/lean/atom.xml" rel="self"/>
  <link href="http://abruzzi.github.com/"/>
  <updated>2018-01-13T16:15:54+08:00</updated>
  <id>http://abruzzi.github.com/</id>
  <author>
    <name><![CDATA[Qiu Juntao]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[测试自动化后，我们还需要QA吗？]]></title>
    <link href="http://abruzzi.github.com/2016/09/what-should-qa-do-in-a-agile-team/"/>
    <updated>2016-09-24T23:43:00+08:00</updated>
    <id>http://abruzzi.github.com/2016/09/what-should-qa-do-in-a-agile-team</id>
    <content type="html"><![CDATA[<h2>QA的职责</h2>

<p>我们先讨论一下传统的瀑布模型下QA是如何工作的，其中最主要的问题是什么；然后作为对比，我们来看看在敏捷团队里QA又是如何工作的，工作重点又是什么；最后，我们详细看一看在新的职责下，QA应该如何做。</p>

<h3>瀑布开发模型</h3>

<p>即使在今天，在很多企业中，瀑布模型仍然是主流。每一个需求都需要经过分析，设计，开发，测试，上线部署，运维等阶段。虽然一些企业已经在实施<code>敏捷开发</code>，比如项目/产品以迭代的方式运作，也有诸如每日站会，代码检视等敏捷实践，但是如果仔细审视，你会发现其实<em>开发模式</em>骨子里还是瀑布：按照软件组件划分的部门结构（详见<a href="https://en.wikipedia.org/wiki/Conway%27s_law">康威定律</a>），按照职能划分的团队（开发和测试分属不同部门），过长的反馈周期，永远无法摆脱的集成难题等等。</p>

<p>随着软件变得越来越复杂，团队里没有任何一个人可以说出系统是如何运作的，也不知道最终用户是谁，以及最终用户会以何种方式来使用最终的软件。</p>

<p>更糟糕的是，按照职能划分的团队在物理上都是隔离的，比如独立的测试部门，独立的运维部门，整日忙碌而难以预约到档期的业务人员，当然还有经常疲于交付，无处吐槽的<em>苦逼</em>开发。由于这些隔离，信息的反馈周期会非常长，一个本来很容易修复的缺陷可能在4周之后才可能被另一个部门的测试发现，然后通过复杂的工作流（比如某种形式的缺陷追踪系统）流到开发那里，而开发可能还在拼命的完成早就应该交付的功能，从而形成恶性循环。</p>

<h3>瀑布模式中的QA</h3>

<p>在这样的环境中，QA们能做的事情非常有限。在需求开始时会他们参加需求澄清的会议，制定一些<code>测试计划</code>，然后进行测试用例的设计。有的企业会用诸如Excel之类的工具来记录这些用例。这些写在Excel里的，<code>死</code>的用例用处非常有限。而最大的问题在于：它们无法<code>自动化执行</code>。另外，在实际软件开发中，需求总是会经常发生变化，需求的优先级也会有调整，然后这些记录在Excel中的<code>死</code>的用例会很快过期，变得无人问津。</p>

<p>除此之外，QA中的有些成员会使用工具来录制一些UI测试的场景，然后在每个新版本出来之后进行回放即可。然而，当UI发生一点变化之后，这些自动化的用例就会失效：比如<code>HTML</code>片段中元素位置的调整，<code>JavaScript</code>的异步调用超时等等。</p>

<p>显然，这种单纯以黑盒的形式来<strong>检查功能点</strong>的测试方式是不工作的，要真正有效的提升软件质量，仅仅通过<strong>事后检查</strong>是远远不够的，软件的质量也应该内建于软件之中。QA的工作也应该是一个贯穿软件生命周期的活动，从商业想法，到真实上线，这其中的所有环节，都应该有QA的参与。</p>

<h3>系统思考</h3>

<p>如果不从一个系统的角度来思考软件质量，就无法真正构建出健壮的、让业务和团队都有信心的软件系统。<strong><em>质量从来都不只是QA的职责，而是整个团队的职责。</em></strong></p>

<p>关于软件质量，一个根深蒂固的误解是：缺陷在开发过程中被引入，然后在测试阶段被发现，最后在QA和开发的来来回回的撕扯中被解决（或者数量被大规模降低），最后在生产环境中，就只会有很少的，优先级很低的缺陷。</p>

<p>然而事实上，很多需求就没有仔细分析，业务价值不很确定，验收条件模糊，流入开发后又会引入一些代码级别的错误，以及业务规则上的缺陷，测试阶段会漏掉一些功能点，上线之后更是问题百出（网络故障，缓存失效，黑客攻击，操作系统补丁，甚至内存溢出，log文件将磁盘写满等等）。</p>

<p>在一个敏捷团队中，<strong>每个个人都应该对质量负责</strong>，而QA则以自己的丰富经验和独特视角来发掘系统中可能的质量隐患，并帮助团队将这些隐患消除。</p>

<p><img src="/images/2016/09/circle-resized.png" alt="测试职责" /></p>

<p>我在ThoughtWorks的同事<code>Anand Bagmar</code>在他的演讲<a href="http://www.slideshare.net/abagmar/what-is-agile-testing-how-does-automation-help">What is Agile testing- How does automation help?</a>中详细讨论过这部分内容。</p>

<h3>QA到底应该干什么？</h3>

<p>本质上来说，任何软件项目的目标都应该是：<strong>更快地将<code>高质量</code>的软件从想法变成产品</strong>。</p>

<p>将这个大目标细分一下，会得到这样几个子项，即企业需要：</p>

<ul>
<li>更多的商业回报（发掘业务价值）</li>
<li>更快的上线时间（做最简单，直接的版本）</li>
<li>更好的软件质量（质量内嵌）</li>
<li>更少的资源投入（减少浪费）</li>
</ul>


<p>其实就是传说中的<strong>多、快、好、省</strong>。如果说这是每一个软件项目的目标的话，那么团队里的每一个个人都应该向着这个目标而努力，任何其他形式的工作都可以归类为<code>浪费</code>。用Excel记录那些经常会失效，而且无法自动执行的测试用例是浪费，会因为页面布局变化而大面积失效的UI测试也是浪费，一个容易修复的缺陷要等到数周之后才被发现也是浪费。</p>

<p>在这个大前提下，我们再来思考QA在团队里应该做什么以及怎么做。</p>

<h3>QA的职责</h3>

<p>Lisa Crispin在<a href="https://book.douban.com/subject/5338399/">《敏捷软件测试》</a>中提到过一个很著名的模型：敏捷测试四象限。这个模型是QA制定测试策略时的一个重要参考：</p>

<p><img src="/images/2016/09/agile-testing-quadrants.png" alt="敏捷软件测试" /></p>

<p>如果按照纵向划分的话，图中的活动，越向上越面向业务；越向下越面向技术。横向划分的话，往左是支撑团队；往右是评价产品。</p>

<p>其实简化一下，QA在团队里的工作，可以分为两大类：</p>

<ul>
<li>确保我们在<code>正确的</code>交付产品</li>
<li>确保我们交付了<code>正确的</code>产品</li>
</ul>


<p>根据这个四象限的划分，大部分团队可能都会从Q2起步：QA会和BA，甚至UX一起，从需求分析入手，进行需求分析，业务场景梳理，这时候没有具体的可以被测试的软件代码。不过这并不妨碍<strong>测试</strong>活动，比如一些纸上原型的设计（感谢刘海生供图）：</p>

<p><img src="/images/2016/09/prototype-resized.png" alt="" /></p>

<p>通过这一阶段之后，我们已经有了用户故事，这时候QA需要和开发一起编写用户故事的自动化验收测试。当开发交付一部分功能之后，QA就可以做常规的用户故事测试，几个迭代之后，QA开始进行跨功能需求测试和探索性测试等。根据探索性测试的结果，QA可能会调整测试策略，调整测试优先级，完善测试用例等等。</p>

<p>根据项目的不同，团队可以从不同的象限开始测试策略的制定。事实上，Q1-Q4仅仅是一个编号，与时间、阶段并无关系，Lisa Crispin还专门<a href="http://lisacrispin.com/2011/11/08/using-the-agile-testing-quadrants/">撰文解释</a>过。</p>

<p>关于QA如何在软件分析的上游就介入，然后通过BDD的方式与业务分析师一起产出软件的各种规格描述，并通过实例的方式来帮助整个团队对需求的理解，ThoughtWorks的林冰玉有一篇文章很好的介绍了<a href="http://insights.thoughtworkers.org/when-we-talk-about-bdd/">BDD的正确做法</a>。如果将QA的外延扩展到在线的生产环境，制定合理的测量指标，调整测试策略，强烈推荐林冰玉写的另一篇文章<a href="http://www.jianshu.com/p/20b454a88bdb">产品环境中的QA</a>。</p>

<h4>其他职责</h4>

<p>事实上，软件生命周期中有很多的活动，有很多处于<code>灰色</code>地段。既可以说是应该开发做，又可以说应该QA做，甚至可以推给其他角色（比如OPs）。不过我们知道，一旦涉及角色，人们就再也不会按照<code>全局优化</code>的思路来应对问题了。这种<code>灰色</code>的活动包括：</p>

<ul>
<li>持续集成的搭建</li>
<li>测试环境的创建于维护</li>
<li>UAT上的数据准备</li>
<li>代码中的测试代码的维护</li>
<li>测试代码的重构</li>
</ul>


<p>在团队实践中，这些活动我们通常会让QA和开发或者OPs同事一起结对来完成。一方面避免知识孤岛的形成，另一方面在跨角色的工作中，也可以激发出更多不同的思路。</p>

<h3>万能的QA？</h3>

<p>虽然在这些活动中，QA都会参与，但是并不是说团队里只要有一个QA就可以了。QA在参与这些活动时，侧重点还是有很大不同的。</p>

<p>比如需求分析阶段，如果有QA的加入，一些从QA角度可以发现的有明显缺陷的场景，则可以在分析阶段就得到很好的处理。另一方面，尽早介入可以设计出更合理的测试计划（比如哪些功能的优先级比较高，用户更会频繁使用，那么对应的测试比重也会更高）。在Story分析与书写阶段，QA可以帮助写出更加合理的验收条件，既满足业务需求，又可以很好的指导开发。</p>

<p>在和开发一起编写澄清需求时，主要是编写自动化验收测试，而不是实际编写业务逻辑的实现（虽然QA应该参与<code>Code Reivew</code>环节，学习并分享自己的观点）；甚至在上线运维阶段，QA还需要和OPs一起来设计用户数据的采集指标（比如用户访问的关键路径，浏览器版本，地区的区分等），从而制定出新的测试策略。</p>

<h3>扩展阅读</h3>

<ul>
<li><a href="http://www.slideshare.net/abagmar/what-is-agile-testing-how-does-automation-help">What is Agile testing - How does automation help?</a></li>
<li><a href="http://insights.thoughtworkers.org/agile-showcase-se7en/">敏捷实践Showcase的七宗罪</a></li>
<li><a href="http://www.jianshu.com/p/20b454a88bdb">产品环境下的QA</a></li>
<li><a href="https://book.douban.com/subject/5338399/">《敏捷软件测试》</a></li>
</ul>


<p>P.S. 感谢林冰玉对本文的<code>Review</code>和指导。</p>
]]></content>
  </entry>
  
</feed>
